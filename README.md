# Hand-Gesture-Mouse
This project allows users to control their computer mouse and perform basic actions like cursor movement, clicking, and tab switching using just hand gestures detected via a webcam
Using MediaPipe for real-time hand tracking and PyAutoGUI for system control, the project translates specific gestures (like pinching or swiping) into mouse actions. For example:

Move your index finger to control the cursor.

Pinch your thumb and index finger to perform a left click.

Swipe your hand left or right to switch browser tabs or apps.

This is a beginner-friendly Computer Vision + Human-Computer Interaction (HCI) project that demonstrates how to bridge vision-based input with system-level controls.

ğŸ› ï¸ Technologies Used
Python

OpenCV â€“ for webcam input and image processing

MediaPipe â€“ for hand landmark detection

PyAutoGUI â€“ to control mouse and keyboard

Math (Euclidean Distance) â€“ for gesture detection

ğŸ¯ Features
Hand-based cursor movement

Clicking using pinch gesture

Swipe detection to change browser tabs

Real-time webcam input processing

Works across platforms (Windows, macOS, Linux)

ğŸ“Œ Use Cases
Touchless PC interaction (useful in hygiene-sensitive environments)

Accessibility tools for users with mobility impairments

Educational demos for CV and AI/ML workshops

Prototype for gesture-controlled user interfaces
