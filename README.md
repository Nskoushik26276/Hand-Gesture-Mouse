# Hand-Gesture-Mouse
This project allows users to control their computer mouse and perform basic actions like cursor movement, clicking, and tab switching using just hand gestures detected via a webcam
Using MediaPipe for real-time hand tracking and PyAutoGUI for system control, the project translates specific gestures (like pinching or swiping) into mouse actions. For example:

Move your index finger to control the cursor.

Pinch your thumb and index finger to perform a left click.

Swipe your hand left or right to switch browser tabs or apps.

This is a beginner-friendly Computer Vision + Human-Computer Interaction (HCI) project that demonstrates how to bridge vision-based input with system-level controls.

🛠️ Technologies Used
Python

OpenCV – for webcam input and image processing

MediaPipe – for hand landmark detection

PyAutoGUI – to control mouse and keyboard

Math (Euclidean Distance) – for gesture detection

🎯 Features
Hand-based cursor movement

Clicking using pinch gesture

Swipe detection to change browser tabs

Real-time webcam input processing

Works across platforms (Windows, macOS, Linux)

📌 Use Cases
Touchless PC interaction (useful in hygiene-sensitive environments)

Accessibility tools for users with mobility impairments

Educational demos for CV and AI/ML workshops

Prototype for gesture-controlled user interfaces
